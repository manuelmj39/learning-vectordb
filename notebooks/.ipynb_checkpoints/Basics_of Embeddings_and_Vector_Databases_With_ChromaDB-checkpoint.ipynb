{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ae6028",
   "metadata": {},
   "source": [
    "##  Embeddings and Vector Databases With ChromaDB\n",
    "\n",
    "In this tutorial, we will learn about:\n",
    "* Representing unstructured objects with vectors\n",
    "* Using word and text embeddings in Python\n",
    "* Harnessing the power of vector databases\n",
    "* Encoding and querying over documents with ChromaDB\n",
    "* Providing context to LLMs like ChatGPT with ChromaDB\n",
    "\n",
    "Reference: https://realpython.com/chromadb-vector-database/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b6121",
   "metadata": {},
   "source": [
    "### Vector Basics\n",
    "You can describe vectors with variable levels of complexity, but one great starting place is to think of a vector as an array of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8480f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample Vectors using numpy\n",
    "import numpy as np\n",
    "\n",
    "vec1 = np.array([1, 0])\n",
    "vec2 = np.array([0, 1])\n",
    "\n",
    "vec1 + vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e3297f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e4f63c",
   "metadata": {},
   "source": [
    "**A few keyword to remember:**\n",
    "\n",
    "* Dimension: The dimension of a vector is the number of elements that it contains. In the example above, vector1 and vector2 are both two-dimensional since they each have two elements. You can only visualize vectors with three dimensions or less, but generally, vectors can have any number of dimensions. In fact, as you’ll see later, vectors that encode words and text tend to have hundreds or thousands of dimensions.\n",
    "\n",
    "* Magnitude: The magnitude of a vector is a non-negative number that represents the vector’s size or length. You can also refer to the magnitude of a vector as the norm, and you can denote it with ||v|| or |v|. There are many different definitions of magnitude or norm, but the most common is the Euclidean norm or 2-norm. You’ll learn how to compute this later.\n",
    "\n",
    "* Unit vector: A unit vector is a vector with a magnitude of one. In the example above, vector1 and vector2 are unit vectors.\n",
    "\n",
    "* Direction: The direction of a vector specifies the line along which the vector points. You can represent direction using angles, unit vectors, or coordinates in different coordinate systems.\n",
    "\n",
    "* Dot product (scalar product): The dot product of two vectors, u and v, is a number given by u ⋅ v = ||u|| ||v|| cos(θ), where θ is the angle between the two vectors. Another way to compute the dot product is to do an element-wise multiplication of u and v and sum the results. The dot product is one of the most important and widely used vector operations because it measures the similarity between two vectors. You’ll see more of this later on.\n",
    "\n",
    "* Orthogonal vectors: Vectors are orthogonal if their dot product is zero, meaning that they’re at a 90 degree angle to each other. You can think of orthogonal vectors as being completely unrelated to each other.\n",
    "\n",
    "* Dense vector: A vector is considered dense if most of its elements are non-zero. Later on, you’ll see that words and text are most usefully represented with dense vectors because each dimension encodes meaningful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22f07490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of v1:  (2,)\n",
      "Magnitude of v1:  1.0\n",
      "Magnitude of v1:  1.0\n",
      "Magnitude of v3:  2.0\n",
      "Dot product of v1 and v2:  0\n",
      "Dot product of v1 and v3:  1.4142135623730951\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1, 0])\n",
    "v2 = np.array([0, 1])\n",
    "v3 = np.array([np.sqrt(2), np.sqrt(2)])\n",
    "\n",
    "# Dimension\n",
    "print(\"Dimension of v1: \", v1.shape)\n",
    "\n",
    "\n",
    "# Magnitude\n",
    "print(\"Magnitude of v1: \", np.sqrt(np.sum(v1**2)))\n",
    "\n",
    "print(\"Magnitude of v1: \", np.linalg.norm(v1))\n",
    "\n",
    "\n",
    "print(\"Magnitude of v3: \", np.linalg.norm(v3))\n",
    "\n",
    "\n",
    "# Dot product\n",
    "print(\"Dot product of v1 and v2: \", np.sum(v1 * v2))\n",
    "\n",
    "\n",
    "print(\"Dot product of v1 and v3: \", v1 @ v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a51a6e",
   "metadata": {},
   "source": [
    "### Vector Similarity\n",
    "The foundation for this measurement lies in the dot product, which serves as the bedrock for many vector similarity metrics.\n",
    "\n",
    "One issue with the dot product, when used in isolation, is that it can take on any value and is therefore difficult to interpret in absolute terms. For example, if you know only that the dot product between two vectors is -3, then it’s unclear what that means without more context.\n",
    "\n",
    "To overcome this shortcoming, one common approach is to use cosine similarity, a normalized form of the dot product. You compute cosine similarity by taking the cosine of the angle between two vectors. In essence, you rearrange the cosine definition of the dot product from earlier to solve for cos(θ).\n",
    "\n",
    "\n",
    "Cosine similarity disregards the magnitude of both vectors, forcing the calculation to lie between -1 and 1. This is a really nice property because it gives cosine similarity the following interpretations:\n",
    "\n",
    "* A value of 1 means the angle between the two vectors is 0 degrees. In other words, the two vectors are similar because they point in the exact same direction. Keep in mind this doesn’t mean that the vectors have the same magnitude.\n",
    "\n",
    "* A value of 0 means the angle between the two vectors is 90 degrees. In this case, the vectors are orthogonal and unrelated to each other.\n",
    "\n",
    "* A value of -1 means the angle between the two vectors is 180 degrees. This is an interesting case where the vectors are dissimilar because they point in opposite directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89112c8f",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Embeddings are a way to represent data such as words, text, images, and audio in a numerical format that computational algorithms can more easily process.\n",
    "\n",
    "More specifically, embeddings are dense vectors that characterize meaningful information about the objects that they encode. The most common kinds of embeddings are word and text embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201f992",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "A word embedding is a vector that captures the semantic meaning of word. Ideally, words that are semantically similar in natural language should have embeddings that are similar to each other in the encoded vector space. Analogously, words that are unrelated or opposite of one another should be further apart in the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaac043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of embedding:  <class 'numpy.ndarray'>\n",
      "Shape of Embedding: (300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.2330e+00,  4.2963e+00, -7.9738e+00, -1.0121e+01,  1.8207e+00,\n",
       "        1.4098e+00, -4.5180e+00, -5.2261e+00, -2.9157e-01,  9.5234e-01,\n",
       "        6.9880e+00,  5.0637e+00, -5.5726e-03,  3.3395e+00,  6.4596e+00,\n",
       "       -6.3742e+00,  3.9045e-02, -3.9855e+00,  1.2085e+00, -1.3186e+00,\n",
       "       -4.8886e+00,  3.7066e+00, -2.8281e+00, -3.5447e+00,  7.6888e-01,\n",
       "        1.5016e+00, -4.3632e+00,  8.6480e+00, -5.9286e+00, -1.3055e+00,\n",
       "        8.3870e-01,  9.0137e-01, -1.7843e+00, -1.0148e+00,  2.7300e+00,\n",
       "       -6.9039e+00,  8.0413e-01,  7.4880e+00,  6.1078e+00, -4.2130e+00,\n",
       "       -1.5384e-01, -5.4995e+00,  1.0896e+01,  3.9278e+00, -1.3601e-01,\n",
       "        7.7732e-02,  3.2218e+00, -5.8777e+00,  6.1359e-01, -2.4287e+00,\n",
       "        6.2820e+00,  1.3461e+01,  4.3236e+00,  2.4266e+00, -2.6512e+00,\n",
       "        1.1577e+00,  5.0848e+00, -1.7058e+00,  3.3824e+00,  3.2850e+00,\n",
       "        1.0969e+00, -8.3711e+00, -1.5554e+00,  2.0296e+00, -2.6796e+00,\n",
       "       -6.9195e+00, -2.3386e+00, -1.9916e+00, -3.0450e+00,  2.4890e+00,\n",
       "        7.3247e+00,  1.3364e+00,  2.3828e-01,  8.4388e-02,  3.1480e+00,\n",
       "       -1.1128e+00, -3.5598e+00, -1.2115e-01, -2.0357e+00, -3.2731e+00,\n",
       "       -7.7205e+00,  4.0948e+00, -2.0732e+00,  2.0833e+00, -2.2803e+00,\n",
       "       -4.9850e+00,  9.7667e+00,  6.1779e+00, -1.0352e+01, -2.2268e+00,\n",
       "        2.5765e+00, -5.7440e+00,  5.5564e+00, -5.2735e+00,  3.0004e+00,\n",
       "       -4.2512e+00, -1.5682e+00,  2.2698e+00,  1.0491e+00, -9.0486e+00,\n",
       "        4.2936e+00,  1.8709e+00,  5.1985e+00, -1.3153e+00,  6.5224e+00,\n",
       "        4.0113e-01, -1.2583e+01,  3.6534e+00, -2.0961e+00,  1.0022e+00,\n",
       "       -1.7873e+00, -4.2555e+00,  7.7471e+00,  1.0173e+00,  3.1626e+00,\n",
       "        2.3558e+00,  3.3589e-01, -4.4178e+00,  5.0584e+00, -2.4118e+00,\n",
       "       -2.7445e+00,  3.4170e+00, -1.1574e+01, -2.6568e+00, -3.6933e+00,\n",
       "       -2.0398e+00,  5.0976e+00,  6.5249e+00,  3.3573e+00,  9.5334e-01,\n",
       "       -9.4430e-01, -9.4395e+00,  2.7867e+00, -1.7549e+00,  1.7287e+00,\n",
       "        3.4942e+00, -1.6883e+00, -3.5771e+00, -1.9013e+00,  2.2239e+00,\n",
       "       -5.4335e+00, -6.5724e+00, -6.7228e-01, -1.9748e+00, -3.1080e+00,\n",
       "       -1.8570e+00,  9.9496e-01,  8.9135e-01, -4.4254e+00,  3.3125e-01,\n",
       "        5.8815e+00,  1.9384e+00,  5.7294e-01, -2.8830e+00,  3.8087e+00,\n",
       "       -1.3095e+00,  5.9208e+00,  3.3620e+00,  3.3571e+00, -3.8807e-01,\n",
       "        9.0022e-01, -5.5742e+00, -4.2939e+00,  1.4992e+00, -4.7080e+00,\n",
       "       -2.9402e+00, -1.2259e+00,  3.0980e-01,  1.8858e+00, -1.9867e+00,\n",
       "       -2.3554e-01, -5.4535e-01, -2.1387e-01,  2.4797e+00,  5.9710e+00,\n",
       "       -7.1249e+00,  1.6257e+00, -1.5241e+00,  7.5974e-01,  1.4312e+00,\n",
       "        2.3641e+00, -3.5566e+00,  9.2066e-01,  4.4934e-01, -1.3233e+00,\n",
       "        3.1733e+00, -4.7059e+00, -1.2090e+01, -3.9241e-01, -6.8457e-01,\n",
       "       -3.6789e+00,  6.6279e+00, -2.9937e+00, -3.8361e+00,  1.3868e+00,\n",
       "       -4.9002e+00, -2.4299e+00,  6.4312e+00,  2.5056e+00, -4.5080e+00,\n",
       "       -5.1278e+00, -1.5585e+00, -3.0226e+00, -8.6811e-01, -1.1538e+00,\n",
       "       -1.0022e+00, -9.1651e-01, -4.7810e-01, -1.6084e+00, -2.7307e+00,\n",
       "        3.7080e+00,  7.7423e-01, -1.1085e+00, -6.8755e-01, -8.2901e+00,\n",
       "        3.2405e+00, -1.6108e-01, -6.2837e-01, -5.5960e+00, -4.4865e+00,\n",
       "        4.0115e-01, -3.7063e+00, -2.1704e+00,  4.0789e+00, -1.7973e+00,\n",
       "        8.9538e+00,  8.9421e-01, -4.8128e+00,  4.5367e+00, -3.2579e-01,\n",
       "       -5.2344e+00, -3.9766e+00, -2.1979e+00,  3.5699e+00,  1.4982e+00,\n",
       "        6.0972e+00, -1.9704e+00,  4.6522e+00, -3.7734e-01,  3.9101e-02,\n",
       "        2.5361e+00, -1.8096e+00,  8.7035e+00, -8.6372e+00, -3.5257e+00,\n",
       "        3.1034e+00,  3.2635e+00,  4.5437e+00, -5.7290e+00, -2.9141e-01,\n",
       "       -2.0011e+00,  8.5328e+00, -4.5064e+00, -4.8276e+00, -1.1786e+01,\n",
       "        3.5607e-01, -5.7115e+00,  6.3122e+00, -3.6650e+00,  3.3597e-01,\n",
       "        2.5017e+00, -3.5025e+00, -3.7891e+00, -3.1343e+00, -1.4429e+00,\n",
       "       -6.9119e+00, -2.6114e+00, -5.9757e-01,  3.7847e-01,  6.3187e+00,\n",
       "        2.8965e+00, -2.5397e+00,  1.8022e+00,  3.5486e+00,  4.4721e+00,\n",
       "       -4.8481e+00, -3.6252e+00,  4.0969e+00, -2.0081e+00, -2.0122e-01,\n",
       "        2.5244e+00, -6.8817e-01,  6.7184e-01, -7.0466e+00,  1.6641e+00,\n",
       "       -2.2308e+00, -3.8960e+00,  6.1320e+00, -8.0335e+00, -1.7130e+00,\n",
       "        2.5688e+00, -5.2547e+00,  6.9845e+00,  2.7835e-01, -6.4554e+00,\n",
       "       -2.1327e+00, -5.6515e+00,  1.1174e+01, -8.0568e+00,  5.7985e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "\n",
    "print(\"Type of embedding: \", type(dog_embedding))\n",
    "\n",
    "print(\"Shape of Embedding:\", dog_embedding.shape)\n",
    "\n",
    "dog_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49c1c5",
   "metadata": {},
   "source": [
    "You first import spacy and load the medium English model into an object called nlp. You then look up the embedding for the word dog with nlp.vocab[\"dog\"].vector and store it as dog_embedding. Calling type(dog_embedding) tells you that the embedding is a NumPy array, and dog_embedding.shape indicates that the embedding has 300 dimensions. Lastly, dog_embedding[0:10] shows the values of the first 10 dimensions.\n",
    "\n",
    "This is pretty neat! The nlp.vocab object allows you to find the word embedding for any word in the model’s vocabulary. You can now assess the similarity between word embeddings using metrics like cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d2e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(u: np.ndarray, v: np.ndarray) -> float:\n",
    "    \"\"\"Compute the cosine similarity between two vectors\"\"\"\n",
    "\n",
    "    return (u @ v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f6caed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Vs Dog :  0.8220817\n",
      "Apple Vs Delicious :  0.5347654\n"
     ]
    }
   ],
   "source": [
    "dog_embedding = nlp.vocab[\"dog\"].vector\n",
    "cat_embedding = nlp.vocab[\"cat\"].vector\n",
    "apple_embedding = nlp.vocab[\"apple\"].vector\n",
    "tasty_embedding = nlp.vocab[\"tasty\"].vector\n",
    "delicious_embedding = nlp.vocab[\"delicious\"].vector\n",
    "truck_embedding = nlp.vocab[\"truck\"].vector\n",
    "\n",
    "print(\"Cat Vs Dog : \", compute_cosine_similarity(dog_embedding, cat_embedding))\n",
    "print(\"Apple Vs Delicious : \", compute_cosine_similarity(apple_embedding, delicious_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8662c67",
   "metadata": {},
   "source": [
    "### Text Embeddings\n",
    "Text embeddings encode information about sentences and documents, not just individual words, into vectors. This allows you to compare larger bodies of text to each other just like you did with word vectors. Because they encode more information than a single word embedding, text embeddings are a more powerful representation of information.\n",
    "\n",
    "Text embeddings are typically the fundamental objects stored in vector databases like ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dad0f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manueljohn/opt/anaconda3/envs/mlops/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:  <class 'numpy.ndarray'>\n",
      "Shape:  (4, 384)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = [\n",
    "         \"The canine barked loudly.\",\n",
    "         \"The dog made a noisy bark.\",\n",
    "         \"He ate a lot of pizza.\",\n",
    "         \"He devoured a large quantity of pizza pie.\",\n",
    "]\n",
    "\n",
    "text_embeddings = model.encode(texts)\n",
    "\n",
    "print(\"Type: \", type(text_embeddings))\n",
    "\n",
    "print(\"Shape: \", text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91af516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.15964164e-02, -2.46818159e-02,  7.78930783e-02, -6.14949502e-03,\n",
       "        1.70014743e-02,  1.26202719e-03,  1.23739600e-01, -1.97151094e-03,\n",
       "        5.89809977e-02, -4.21656072e-02,  5.91972917e-02, -7.12989345e-02,\n",
       "        1.26703799e-01,  2.51503158e-02, -1.38013838e-02, -6.40119463e-02,\n",
       "       -2.13553403e-02, -2.36788057e-02, -4.56758700e-02,  7.49071548e-03,\n",
       "       -8.09309781e-02,  1.64253470e-02,  4.02019247e-02,  3.40726860e-02,\n",
       "       -9.14752558e-02,  4.13327254e-02, -2.85369856e-03, -5.18556917e-03,\n",
       "        6.23375550e-02, -3.98614444e-02,  1.68919116e-02,  1.91846248e-02,\n",
       "        5.93932904e-03, -8.97368938e-02,  1.82577427e-02,  4.33312170e-03,\n",
       "        1.75719745e-02, -6.44410774e-02, -6.92551285e-02,  4.20069136e-02,\n",
       "       -6.00515008e-02, -3.75331156e-02,  5.68970330e-02, -6.44810423e-02,\n",
       "        5.67378737e-02,  1.10392459e-02, -7.32904077e-02, -2.01278105e-02,\n",
       "        2.71938723e-02, -1.15391687e-02,  2.39583943e-03,  1.29432669e-02,\n",
       "       -2.86375731e-02,  1.99649893e-02,  3.92318144e-02, -6.87271310e-03,\n",
       "       -4.53365184e-02, -4.93506119e-02, -5.42133767e-03, -6.29054978e-02,\n",
       "       -2.27945056e-02,  1.07592270e-02, -2.36401372e-02,  3.43207531e-02,\n",
       "        4.88936342e-03,  4.67503443e-02, -3.95931024e-03, -2.05627065e-02,\n",
       "        3.36063243e-02,  1.98798236e-02,  3.19051370e-02, -3.54857594e-02,\n",
       "        1.64046735e-02, -7.18353838e-02,  4.03315248e-03,  1.76436156e-02,\n",
       "        1.06105812e-01,  5.71509004e-02,  2.28205752e-02,  7.72664472e-02,\n",
       "        1.92217331e-03,  1.00107433e-03, -3.95386443e-02,  9.43766907e-02,\n",
       "       -7.56036118e-02, -2.29795706e-02, -5.16390763e-02,  4.90746573e-02,\n",
       "        1.50723173e-03,  6.70093298e-02, -2.15758998e-02, -8.75478704e-03,\n",
       "        3.73453386e-02, -4.95842239e-03, -1.43761069e-01,  8.76781717e-03,\n",
       "        2.91172247e-02, -6.84864894e-02, -6.96574152e-02,  2.01606885e-01,\n",
       "        6.97377995e-02,  1.37412697e-02,  4.60006744e-02,  2.86064278e-02,\n",
       "       -6.50032461e-02, -3.18027474e-02, -5.56337973e-03, -2.67155990e-02,\n",
       "        5.69047555e-02,  5.33103943e-03, -3.94300185e-02, -9.03777331e-02,\n",
       "       -5.60249388e-02, -4.27228697e-02,  9.39270854e-02,  3.98916006e-02,\n",
       "       -1.09253991e-02,  1.32021494e-02, -5.67860827e-02,  1.33165894e-02,\n",
       "        5.40728718e-02,  2.26058699e-02, -3.29375006e-02, -2.86720358e-02,\n",
       "       -6.06594644e-02, -5.20343818e-02, -1.10096876e-02, -3.73217546e-33,\n",
       "       -5.34542985e-02,  1.92474201e-02, -1.19104963e-02, -5.14244512e-02,\n",
       "       -5.69194146e-02,  9.40398574e-02, -2.07467005e-02,  9.04024672e-03,\n",
       "       -8.25830773e-02,  2.50013992e-02, -2.17744857e-02,  3.21462341e-02,\n",
       "       -3.05216331e-02, -6.43467382e-02,  1.39680197e-02,  2.18319474e-03,\n",
       "       -1.43816872e-02, -9.54910740e-03,  3.33024897e-02,  4.30441927e-03,\n",
       "        1.30004790e-02, -9.49802473e-02,  1.92894205e-03,  5.27398884e-02,\n",
       "       -1.87414046e-02, -3.25929783e-02,  2.04927530e-02, -5.21094985e-02,\n",
       "       -7.24973828e-02,  6.64855773e-03,  4.00967970e-02,  1.19001856e-02,\n",
       "       -2.47485489e-02,  5.97316846e-02, -7.55826235e-02, -6.17458522e-02,\n",
       "        1.06104597e-01,  3.00547089e-02, -3.64544131e-02,  9.22854543e-02,\n",
       "        5.46000153e-02, -7.35953674e-02, -1.01647943e-01, -6.72575980e-02,\n",
       "        3.29585746e-02,  7.05811381e-02, -8.59232154e-03, -8.06124955e-02,\n",
       "        1.87250394e-02,  1.66639592e-02, -2.78080031e-02,  5.52182421e-02,\n",
       "       -1.17821589e-01,  4.96946834e-02,  6.87439367e-02, -2.93182097e-02,\n",
       "        4.40473147e-02, -1.56600261e-03, -4.30615954e-02, -1.43424775e-02,\n",
       "        2.77926866e-02, -2.18410268e-02, -1.27367247e-02, -4.89472644e-03,\n",
       "       -7.75244981e-02, -3.58185954e-02,  3.52664292e-02, -1.62749942e-02,\n",
       "        3.59971449e-02, -7.69982338e-02, -3.64634991e-02,  1.93151105e-02,\n",
       "        1.44903317e-01,  4.34132554e-02, -5.06852493e-02, -5.70323355e-02,\n",
       "       -1.40590137e-02,  3.62634659e-02,  9.07167345e-02,  1.87139139e-02,\n",
       "        3.70121822e-02, -5.97235784e-02,  3.98529805e-02, -1.06286108e-01,\n",
       "        5.54446019e-02,  8.16215947e-03,  6.54172199e-03, -1.36662409e-01,\n",
       "        1.34027069e-02, -3.60875577e-02, -1.05152123e-01, -4.10749689e-02,\n",
       "        1.06852375e-01,  4.15198393e-02, -2.88872533e-02,  1.72088204e-33,\n",
       "        2.64808051e-02,  4.88158576e-02,  5.49002783e-03, -1.39161828e-03,\n",
       "       -5.29707409e-02, -2.14584414e-02,  2.44858600e-02,  7.47256726e-02,\n",
       "       -1.44588603e-02,  1.59048699e-02,  8.27717260e-02, -9.76505782e-03,\n",
       "       -3.27097438e-02,  4.58139852e-02,  6.65973034e-03,  5.83911538e-02,\n",
       "        9.90266427e-02,  5.49561754e-02, -2.18433272e-02, -1.02028558e-02,\n",
       "        4.44962550e-03, -6.06770106e-02, -5.12825698e-02,  3.62422243e-02,\n",
       "       -2.61908602e-02,  8.49090219e-02,  4.89030480e-02,  3.19696367e-02,\n",
       "        1.24685131e-02,  4.40486558e-02,  3.85332154e-03,  6.62960159e-03,\n",
       "       -2.90031601e-02, -3.17625888e-02, -3.62007618e-02, -1.69580560e-02,\n",
       "       -4.74652648e-02,  2.82131936e-02, -5.21279797e-02,  4.40400355e-02,\n",
       "        2.37164218e-02, -3.08618806e-02,  6.03923500e-02,  1.41249061e-01,\n",
       "        1.90097783e-02,  4.03224677e-02, -5.32910787e-02,  8.04791600e-03,\n",
       "        4.45878208e-02,  1.56979524e-02, -5.87400165e-04, -7.98260048e-02,\n",
       "        1.97161995e-02, -2.36102082e-02, -4.72011918e-04,  3.36594060e-02,\n",
       "        9.35736392e-03,  3.09348442e-02, -9.22561996e-03, -7.09807593e-03,\n",
       "       -9.39008445e-02, -6.19802484e-03, -2.78639067e-02,  7.02157915e-02,\n",
       "       -2.12613009e-02, -3.44924815e-02, -2.45211571e-02, -6.15876615e-02,\n",
       "       -1.56889117e-04, -8.33183005e-02,  1.34555727e-01,  4.80495906e-03,\n",
       "       -1.17199495e-01,  1.03311893e-02, -7.00825751e-02,  4.68557291e-02,\n",
       "       -1.52541101e-02,  5.64465225e-02,  3.54314111e-02,  2.78245118e-02,\n",
       "       -3.14101577e-02,  4.31466475e-02,  1.30901020e-02, -8.88237506e-02,\n",
       "       -2.45955605e-02, -8.59897807e-02,  2.66160909e-02,  5.83984656e-03,\n",
       "       -3.58688980e-02, -9.77010466e-03,  3.21938880e-02,  1.13532580e-01,\n",
       "        3.59047987e-02, -1.01306424e-01, -8.43676552e-03, -1.39154812e-08,\n",
       "       -1.68029722e-02, -3.53371650e-02,  3.90531868e-02, -2.63823811e-02,\n",
       "        4.22832966e-02,  2.91389674e-02, -1.20763741e-01,  2.84231845e-02,\n",
       "        9.12986323e-02,  1.20961107e-02,  1.04159772e-01,  6.55013919e-02,\n",
       "       -3.51495184e-02,  5.31584732e-02,  4.53635177e-04, -4.09805775e-02,\n",
       "        1.09622478e-02,  9.50491428e-02,  1.81363691e-02, -7.43846819e-02,\n",
       "        7.73259252e-02, -1.66576877e-02, -2.21337490e-02,  7.24461628e-03,\n",
       "       -3.78490724e-02,  5.25464751e-02, -6.02953099e-02,  3.76828276e-02,\n",
       "       -1.78525597e-02, -4.42024358e-02,  7.46840052e-03, -5.27351573e-02,\n",
       "        1.11504607e-02,  3.72625068e-02, -1.57440435e-02, -6.70154765e-02,\n",
       "       -1.47206327e-02,  6.33604452e-02, -1.03684561e-03,  3.92680876e-02,\n",
       "       -4.53215428e-02, -2.48916866e-03,  6.80537969e-02, -7.79910851e-03,\n",
       "       -1.08612068e-02, -5.60918599e-02,  3.72916684e-02,  5.77775352e-02,\n",
       "       -4.27025221e-02, -1.46937771e-02, -2.24824226e-03,  5.93009628e-02,\n",
       "        2.80024391e-02,  5.27157485e-02,  4.72511649e-02,  3.30715701e-02,\n",
       "        3.13442945e-02,  4.89197597e-02,  1.09561188e-02,  4.20348085e-02,\n",
       "        1.12500526e-01,  4.77315709e-02, -8.58098548e-03,  6.37517544e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode('hey'*600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91b1cd",
   "metadata": {},
   "source": [
    "While all the texts in this example are single sentences, you can encode longer texts up to a specified word length. For example, \"all-MiniLM-L6-v2\" encodes texts up to 256 words. It’ll truncate any text longer than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1ee26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between dog related texts:  0.77686167\n",
      "Similaroity between Pizza Texts:  0.787134\n",
      "Similaroity between Pizza Text and Dog Text:  0.11757195\n"
     ]
    }
   ],
   "source": [
    "text_embeddings_dict = dict(zip(texts, list(text_embeddings)))\n",
    "\n",
    "dog_text_1 = \"The canine barked loudly.\"\n",
    "dog_text_2 = \"The dog made a noisy bark.\"\n",
    "\n",
    "print(\"Similarity between dog related texts: \", compute_cosine_similarity(text_embeddings_dict[dog_text_1],\n",
    "                          text_embeddings_dict[dog_text_2]))\n",
    "\n",
    "\n",
    "pizza_text_1 = \"He ate a lot of pizza.\"\n",
    "pizza_test_2 = \"He devoured a large quantity of pizza pie.\"\n",
    "\n",
    "print(\"Similaroity between Pizza Texts: \", compute_cosine_similarity(text_embeddings_dict[pizza_text_1],\n",
    "                          text_embeddings_dict[pizza_test_2]))\n",
    "\n",
    "print(\"Similaroity between Pizza Text and Dog Text: \", compute_cosine_similarity(text_embeddings_dict[dog_text_1],\n",
    "                          text_embeddings_dict[pizza_test_2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55c28a",
   "metadata": {},
   "source": [
    "* The cosine similarity between The canine barked loudly and The dog made a noisy bark is relatively high even though the two sentences use different words. The same is true for the similarity between He ate a lot of pizza and He devoured a large quantity of pizza pie. Because the text embeddings encode semantic meaning, any pair of related texts should have a high cosine similarity.\n",
    "\n",
    "* As you might expect, the cosine similarity between The canine barked loudly and He ate a lot of pizza is low because the sentences are unrelated to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ce9b55",
   "metadata": {},
   "source": [
    "## ChromaDB\n",
    "\n",
    "### Vector Database\n",
    "\n",
    "A vector database is a database that allows you to efficiently store and query embedding data. Vector databases extend the capabilities of traditional relational databases to embeddings. However, the key distinguishing feature of a vector database is that query results aren’t an exact match to the query. Instead, using a specified similarity metric, the vector database returns embeddings that are similar to a query.\n",
    "\n",
    "As an example use case, suppose you’ve stored company documents in a vector database. This means each document has been embedded and can be compared to other embeddings through a similarity metric like cosine similarity.\n",
    "\n",
    "Here are the core components of a vector database that you should know about:\n",
    "\n",
    "* **Embedding function**: When using a vector database, oftentimes you’ll store and query data in its raw form, rather than uploading embeddings themselves. Internally, the vector database needs to know how to convert your data to embeddings, and you have to specify an embedding function for this. For text, you can use the embedding functions available in the SentenceTransformers library or any other function that maps raw text to vectors.\n",
    "\n",
    "* **Similarity metric**: To assess embedding similarity, you need a similarity metric like cosine similarity, the dot product, or Euclidean distance. As you learned previously, cosine similarity is a popular choice, but choosing the right similarity metric depends on your application.\n",
    "\n",
    "* **Indexing**: When you’re dealing with a large number of embeddings, comparing a query embedding to every embedding stored in the database is often too slow. To overcome this, vector databases employ indexing algorithms that group similar embeddings together. At query time, the query embedding is compared to a smaller subset of embeddings based on the index. Because the embeddings recommended by the index aren’t guaranteed to have the highest similarity to the query, this is called approximate nearest neighbor search.\n",
    "\n",
    "* **Metadata**: You can store metadata with each embedding to help give context and make query results more precise. You can filter your embedding searches on metadata much like you would in a relational database. For example, you could store the year that a document was published as metadata and only look for similar documents that were published in a given year.\n",
    "\n",
    "* **Storage location**: With any kind of database, you need a place to store the data. Vector databases can store embeddings and metadata both in memory and on disk. Keeping data in memory allows for faster reads and writes, while writing to disk is important for persistent storage.\n",
    "\n",
    "* **CRUD operations**: Most vector databases support create, read, update, and delete (CRUD) operations. This means you can maintain and interact with data like you would in a relational database.\n",
    "\n",
    "**ChromaDB** is an open-source vector database designed specifically for LLM applications. ChromaDB offers you both a user-friendly API and impressive performance, making it a great choice for many embedding applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd400e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "#set up paths, model..\n",
    "CHROMA_DATA_PATH = \"chroma_data/\"\n",
    "EMBED_MODEL = \"all-MiniLM-L6-v2\"\n",
    "COLLECTION_NAME = \"demo_docs\"\n",
    "\n",
    "client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa15210",
   "metadata": {},
   "source": [
    "You then instantiate a PersistentClient object that writes your embedding data to CHROMA_DB_PATH. By doing this, you ensure that data will be stored at CHROMA_DB_PATH and persist to new clients. Alternatively, you can use chromadb.Client() to instantiate a ChromaDB instance that only writes to memory and doesn’t persist on disk.\n",
    "\n",
    "Next, you instantiate your embedding function and the ChromaDB collection to store your documents in:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4dbc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manueljohn/opt/anaconda3/envs/mlops/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(EMBED_MODEL)\n",
    "\n",
    "#define collection\n",
    "collection = client.create_collection(\n",
    "    name=COLLECTION_NAME,\n",
    "    embedding_function=embedding_func,\n",
    "    metadata={\"hnsw:space\": \"cosine\"},)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43af43a",
   "metadata": {},
   "source": [
    " collection is the object that stores your embedded documents along with any associated metadata. If you’re familiar with relational databases, then you can think of a collection as a table. In this example, your collection is named demo_docs, it uses the \"all-MiniLM-L6-v2\" embedding function that you instantiated, and it uses the cosine similarity distance function as specified by metadata={\"hnsw:space\": \"cosine\"}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7744c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: id0\n",
      "Add of existing embedding ID: id1\n",
      "Add of existing embedding ID: id2\n",
      "Add of existing embedding ID: id3\n",
      "Add of existing embedding ID: id4\n",
      "Add of existing embedding ID: id5\n",
      "Add of existing embedding ID: id6\n",
      "Add of existing embedding ID: id7\n",
      "Add of existing embedding ID: id8\n",
      "Add of existing embedding ID: id9\n",
      "Insert of existing embedding ID: id0\n",
      "Insert of existing embedding ID: id1\n",
      "Insert of existing embedding ID: id2\n",
      "Insert of existing embedding ID: id3\n",
      "Insert of existing embedding ID: id4\n",
      "Insert of existing embedding ID: id5\n",
      "Insert of existing embedding ID: id6\n",
      "Insert of existing embedding ID: id7\n",
      "Insert of existing embedding ID: id8\n",
      "Insert of existing embedding ID: id9\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"The latest iPhone model comes with impressive features and a powerful camera.\",\n",
    "    \"Exploring the beautiful beaches and vibrant culture of Bali is a dream for many travelers.\",\n",
    "    \"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
    "    \"Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.\",\n",
    "    \"The American Revolution had a profound impact on the birth of the United States as a nation.\",\n",
    "    \"Regular exercise and a balanced diet are essential for maintaining good physical health.\",\n",
    "    \"Leonardo da Vinci's Mona Lisa is considered one of the most iconic paintings in art history.\",\n",
    "    \"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
    "    \"Startup companies often face challenges in securing funding and scaling their operations.\",\n",
    "    \"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\",\n",
    "]\n",
    "\n",
    "genres = [\n",
    "    \"technology\",\n",
    "    \"travel\",\n",
    "    \"science\",\n",
    "    \"food\",\n",
    "    \"history\",\n",
    "    \"fitness\",\n",
    "    \"art\",\n",
    "    \"climate change\",\n",
    "    \"business\",\n",
    "    \"music\",\n",
    "]\n",
    "\n",
    "#Add data to DB\n",
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=[f\"id{i}\" for i in range(len(documents))],\n",
    "    metadatas=[{\"genre\": g} for g in genres]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5105c85",
   "metadata": {},
   "source": [
    "In this block, you define a list of ten documents in documents and specify the genre of each document in genres. You then add the documents and genres using collection.add(). Each document in the documents argument is embedded and stored in the collection. You also have to define the ids argument to uniquely identify each document and embedding in the collection. You accomplish this with a list comprehension that creates a list of ID strings.\n",
    "\n",
    "The metadatas argument is optional, but most of the time, it’s useful to store metadata with your embeddings. In this case, you define a single metadata field, \"genre\", that records the genre of each document. When you query a document, metadata provides you with additional information that can be helpful to better understand the document’s contents. You can also filter on metadata fields, just like you would in a relational database query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2603026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3']],\n",
       " 'distances': [[0.4305993757604256]],\n",
       " 'metadatas': [[{'genre': 'food'}]],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Traditional Italian pizza is famous for its thin crust, fresh ingredients, and wood-fired ovens.']],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query database\n",
    "query_results = collection.query(\n",
    "    query_texts=[\"Find me some delicious pizza!\"],\n",
    "    n_results=1,\n",
    ")\n",
    "\n",
    "query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9461830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id2', 'id4'], ['id7', 'id2']],\n",
       " 'distances': [[0.6265882785638517, 0.6904193065163069],\n",
       "  [0.8002944119697346, 0.8882106526920683]],\n",
       " 'metadatas': None,\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"Einstein's theory of relativity revolutionized our understanding of space and time.\",\n",
       "   'The American Revolution had a profound impact on the birth of the United States as a nation.'],\n",
       "  [\"Climate change poses a significant threat to the planet's ecosystems and biodiversity.\",\n",
       "   \"Einstein's theory of relativity revolutionized our understanding of space and time.\"]],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_results = collection.query(\n",
    "    query_texts=[\"Teach me about history\",\n",
    "                 \"What's going on in the world?\"],\n",
    "    include=[\"documents\", \"distances\"],\n",
    "    n_results=2\n",
    ")\n",
    "\n",
    "query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d80815",
   "metadata": {},
   "source": [
    "**Keep in mind that so-called similar documents returned from a semantic search over embeddings may not actually be relevant to the task that you’re trying to solve. The success of a semantic search is somewhat subjective, and you or your stakeholders might not agree on the quality of the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc126cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result without metadata:  {'ids': [['id2']], 'distances': [[0.7625819974843479]], 'metadatas': None, 'embeddings': None, 'documents': [[\"Einstein's theory of relativity revolutionized our understanding of space and time.\"]], 'uris': None, 'data': None} \n",
      " \n",
      "Result with metadata:  {'ids': [['id9']], 'distances': [[0.818632860764435]], 'metadatas': None, 'embeddings': None, 'documents': [[\"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\"]], 'uris': None, 'data': None} \n",
      "\n",
      "Result with extra metadata:  {'ids': [['id9', 'id4']], 'distances': [[0.818632860764435, 0.8200413343809558]], 'metadatas': None, 'embeddings': None, 'documents': [[\"Beethoven's Symphony No. 9 is celebrated for its powerful choral finale, 'Ode to Joy.'\", 'The American Revolution had a profound impact on the birth of the United States as a nation.']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "#Filtering on metadata\n",
    "query_results = collection.query(\n",
    "    query_texts=\"Teach me about music history\",\n",
    "    include=[\"documents\", \"distances\"],\n",
    "    n_results=1\n",
    ")\n",
    "print(\"Result without metadata: \", query_results, '\\n ')\n",
    "\n",
    "#metadata equals music\n",
    "query_results = collection.query(\n",
    "    query_texts=\"Teach me about music history\",\n",
    "    include=[\"documents\", \"distances\"],\n",
    "    where={'genre': {'$eq':'music'}},\n",
    "    n_results=2\n",
    ")\n",
    "print(\"Result with metadata: \", query_results, '\\n')\n",
    "\n",
    "#filter in a list of metadata\n",
    "query_results = collection.query(\n",
    "    query_texts=\"Teach me about music history\",\n",
    "    include=[\"documents\", \"distances\"],\n",
    "    where={'genre': {'$in':['music', 'history']}},\n",
    "    n_results=2\n",
    ")\n",
    "print(\"Result with extra metadata: \", query_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f3fd9",
   "metadata": {},
   "source": [
    "This query filters the collection of documents that have either a music or history genre, as specified by where={\"genre\": {\"$in\": [\"music\", \"history\"]}}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db59e33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The new iPhone is awesome!', 'Bali has beautiful beaches']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update existing document\n",
    "collection.update(\n",
    "    ids=[\"id1\", \"id2\"],\n",
    "    documents=[\"The new iPhone is awesome!\",\n",
    "               \"Bali has beautiful beaches\"],\n",
    "    metadatas=[{\"genre\": \"tech\"}, {\"genre\": \"beaches\"}]\n",
    ")\n",
    "\n",
    "query_results = collection.get(ids=[\"id1\", \"id2\"])\n",
    "\n",
    "query_results[\"documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d8a67e",
   "metadata": {},
   "source": [
    " If you’re not sure whether a document exists for an ID, you can use collection.upsert(). This works the same way as collection.update(), except it’ll insert new documents for IDs that don’t exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22ca7891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': None,\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deleting a doxument\n",
    "collection.delete(ids=[\"id0\", \"id1\"])\n",
    "\n",
    "collection.get(ids=[\"id0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e4a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
